#!/usr/bin/env ruby
require 'rubygems'
require 'bundler/setup'
require 'slugify'
require_relative '../lib/helper_download'
require_relative '../lib/helper_extract'
require_relative '../lib/helper_selector'

# Custom selector set to get all the record data from the HTML page
class SmashingSelector
  include HelperSelector

  def initialize
    @website = 'www.smashingmagazine.com'
  end

  # MANDATORY
  # The filename is a sanitized version of the url, without prefix and protocol
  def filename(data)
    object_id = data['objectID']
    return false if object_id.nil?
    filename = object_id.gsub(%r{^https?://#{@website}/}, '')
    filename = filename.gsub(%r{/$}, '')
    filename.gsub('/',  '_')
  end

  # OPTIONAL
  # Custom check of the data to see if we should save the save the record on
  # disk or just skip it
  def save_record?(data, _file)
    if data['objectID'].nil?
      puts 'No objectID'
      return false
    end
    if data['publishedDate'].nil?
      puts 'No publishedDate'
      return false
    end
    if data['title'].nil?
      puts 'No title'
      return false
    end
    if data['url'] !~ %r{^https?://#{@website}}
      puts 'Not on smashingmagazine.com'
      return false
    end
    true
  end

  # The unique objectID identifier
  def record_object_id(doc)
    attribute(doc, 'meta[property="og:url"]', 'content')
  end

  # The page url
  def record_url(doc)
    record_object_id(doc)
  end

  # Image
  def record_image(doc)
    attribute(doc, 'meta[name="twitter:image"]', 'content')
  end

  # The page title
  def record_title(doc)
    title = attribute(doc, 'meta[property="og:title"]', 'content')
    return nil if title.nil?
    title = title.gsub(' â€“ Smashing Magazine', '')
    title
  end

  # The published date of the article
  def record_published_date(doc)
    string_date = attribute(doc,
                            'meta[property="article:published_time"]',
                            'content')
    return nil if string_date.nil?
    DateTime.parse(string_date).to_time.to_i
  end
  
  # The reduced precision published date of the article
  def record_published_date_reduced_precision(doc)
    string_date = attribute(doc,
                            'meta[property="article:published_time"]',
                            'content')
    return nil if string_date.nil?
    DateTime.parse(string_date).to_time.to_i.to_s.slice(0, 2).to_i
  end

  # The author
  def record_author(doc)
    element(doc, 'li[property=author] a[rel=author]').text
  end

  # Author url
  def record_author_url(doc)
    attribute(doc, 'li[property=author] a[rel=author]', 'href')
  end

  # Tags
  def record_tags(doc)
    tags = []
    element(doc, 'meta[property="article:tag"]').map do |meta|
      name = attribute(doc, meta, 'content')
      tags << {
        name: name,
        slug: name.slugify
      }
    end
    tags
  end

  # Number of comments
  def record_comment_count(doc)
    target_node = element(doc, 'li.comments[property=discussionUrl]')
    target_node.text.gsub(' Comments', '').strip.to_i
  end

  # Description
  def record_description(doc)
    description = attribute(doc, 'meta[property="og:description"]', 'content')
    truncate(description)
  end
end

files = HelperDownload.all_files
HelperExtract.new(SmashingSelector.new).extract(files)
